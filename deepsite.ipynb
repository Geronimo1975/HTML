{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f71f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    import os\n",
    "    from langchain_core.messages import SystemMessage, HumanMessage\n",
    "    from dotenv import load_dotenv\n",
    "    from langchain_deepseek import ChatDeepSeek\n",
    "    \n",
    "    load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657e3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Create a chatbot for customer service for a handmade dools store. The chatbot should be able to answer questions about the products, shipping, and returns. It should also be able to take orders and provide tracking information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3c595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dci-student/HTML/html_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3519: UserWarning: WARNING! endpoint is not default parameter.\n",
      "                endpoint was transferred to model_kwargs.\n",
      "                Please confirm that endpoint is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "deep_seek_model = ChatDeepSeek(\n",
    "        endpoint = os.getenv(\"DEEPSEEK_ENDPOINT\"),\n",
    "        api_key = os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "        model= \"DeepSeek-R1\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=4000,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb413a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m response \u001b[38;5;241m=\u001b[39m deep_seek_model\u001b[38;5;241m.\u001b[39mstream(messages)\n\u001b[1;32m     30\u001b[0m website_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[1;32m     32\u001b[0m     website_code \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m website_code\n",
      "File \u001b[0;32m~/HTML/html_env/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:495\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     input_messages \u001b[38;5;241m=\u001b[39m _normalize_messages(messages)\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(input_messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    497\u001b[0m             chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_LC_ID_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/HTML/html_env/lib/python3.10/site-packages/langchain_deepseek/chat_models.py:277\u001b[0m, in \u001b[0;36mChatDeepSeek._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_stream\u001b[39m(\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    271\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    275\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatGenerationChunk]:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    278\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\n\u001b[1;32m    282\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSeek API returned an invalid response. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the API status and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m             e\u001b[38;5;241m.\u001b[39mdoc,\n\u001b[1;32m    285\u001b[0m             e\u001b[38;5;241m.\u001b[39mpos,\n\u001b[1;32m    286\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/HTML/html_env/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:875\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, stream_usage, **kwargs)\u001b[0m\n\u001b[1;32m    873\u001b[0m         base_generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 875\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m response\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/HTML/html_env/lib/python3.10/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'endpoint'"
     ]
    }
   ],
   "source": [
    "def stream_response(prompt, model=\"DeepSeek-R1\"):\n",
    "    \n",
    "    if model == \"DeepSeek-R1\":\n",
    "        deep_seek_model = ChatDeepSeek(\n",
    "            endpoint = os.getenv(\"DEEPSEEK_ENDPOINT\"),\n",
    "            api_key = os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "            model= \"DeepSeek-R1\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=4000,\n",
    "        )\n",
    "    else:\n",
    "        deep_seek_model = ChatDeepSeek(\n",
    "            endpoint = os.getenv(\"DEEPSEEK_ENDPOINT\"),\n",
    "            api_key = os.getenv(\"DEEPSEEK_API_KEY\"),\n",
    "            model= model,\n",
    "            temperature=0.7,\n",
    "            max_tokens=4000,\n",
    "        )\n",
    "    \n",
    "    system_prompt= \"\"\"\n",
    "    ONLY USE HTML, CSS AND JAVASCRIPT. If you want to use ICON make sure to import the library first. Try to create the best UI possible by using only HTML, CSS and JAVASCRIPT. Use as much as you can TailwindCSS for the CSS, if you can't do something with TailwindCSS, then use custom CSS (make sure to import <script src=\"https://cdn.tailwindcss.com\"></script> in the head). Also, try to ellaborate as much as you can, to create something unique. ALWAYS GIVE THE RESPONSE INTO A SINGLE HTML FILE\n",
    "    \"\"\"\n",
    "\n",
    "messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "response = deep_seek_model.stream(messages)\n",
    "\n",
    "website_code = \"\"\n",
    "for chunk in response:\n",
    "    website_code += chunk.content\n",
    "    \n",
    "return website_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8475b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Create a chatbot for customer service for a handmade dools store. The chatbot should be able to answer questions about the products, shipping, and returns. It should also be able to take orders and provide tracking information.\"\n",
    "code = stream_response(prompt)\n",
    "print(code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
